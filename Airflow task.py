from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta
from airflow.utils.dates import days_ago

# Import task functions from assignment.py
from assignment import catalog, combine, titles, clean, count_words

def catalog():
    # Define the pull(url) function
    def pull(url):
        # Function to pull data from a URL
        response = requests.get(url)
        if response.status_code == 200:
            return response.content
        else:
            print(f"Error: Failed to retrieve data from URL {url}")
            return None

    # Define the store(data, file) function
    def store(data, file):
        # Function to store data in a file
        with open(file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"Data stored successfully in {file}")

    # Example usage of pull() and store() functions
    url = "https://https://catalog.mit.edu/subjects/"
    data = pull(url)
    if data:
        store(data, 'data.json')


from bs4 import BeautifulSoup
import requests

def titles():
    # URL to scrape
    url = "https://example.com"

    # Send a GET request to the URL
    response = requests.get(url)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse the HTML content of the page using BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')

        # Find all <title> tags in the HTML content
        title_tags = soup.find_all('title')

        # Extract and print the text of each <title> tag
        for title_tag in title_tags:
            print(title_tag.text)
    else:
        print("Error: Failed to retrieve web page")

def titles():
      from bs4 import BeautifulSoup
      def store_json(data,file):
           with open(file, 'w', encoding='utf-8') as f:
               json.dump(data, f, ensure_ascii=False, indent=4)
               print('wrote file: ' + file)

    import glob

def combine():
    # Open a new file named 'combo.txt' in write mode
    with open('combo.txt', 'w') as outfile:
        # Loop through all HTML files in the current directory
        for file in glob.glob("*.html"):
            # Open each HTML file in read mode
            with open(file, 'r') as infile:
                # Read the contents of the HTML file and write them to 'combo.txt'
                outfile.write(infile.read())

   #Open and read the large html file generated by combine()


   #the following replaces new line and carriage return char
   html = html.replace('\n', ' ').replace('\r', '')
   #the following create an html parser
   soup = BeautifulSoup(html, "html.parser")
   results = soup.find_all('h3')
   titles = []

   # tag inner text
   for item in results:
       titles.append(item.text)
   store_json(titles, 'titles.json')

   def titles():
    def store_json(data, file):
        with open(file, 'w', encoding='utf-8') as f:

# Open and read the large HTML file generated by combine()
    with open('combo.txt', 'r') as f:
        html = f.read()

    # Replace new line and carriage return characters
    html = html.replace('\n', ' ').replace('\r', '')

    # Create an HTML parser
    soup = BeautifulSoup(html, "html.parser")

    # Find all <h3> tags in the HTML content
    results = soup.find_all('h3')
    titles = []

    # Extract the inner text of each <h3> tag
    for item in results:
        titles.append(item.text)

    # Store the extracted titles in a JSON file
    store_json(titles, 'titles.json')
# Open and load titles from 'titles.json'
    with open('titles.json', 'r') as file:
        titles = json.load(file)

        # Remove punctuation/numbers
        for index, title in enumerate(titles):
            punctuation = '''!()-[]{};:'"\,<>./?@#$%^&*_~1234567890'''
            translationTable = str.maketrans("", "", punctuation)
            clean = title.translate(translationTable)
            titles[index] = clean

        # Remove one-character words
        for index, title in enumerate(titles):
            clean = ' '.join([word for word in title.split() if len(word) > 1])
            titles[index] = clean

        # Store cleaned titles in 'titles_clean.json'
        store_json(titles, 'titles_clean.json)

 # List of URLs
    urls = [
        "https://catalog.mit.edu/subjects/"
    ]

    # Iterate through the URLs
    for url in urls:
        # Extract filename from URL
        index = url.rfind('/') + 1
        filename = url[index:]

        # Pull data from URL
        data = pull(url)
        if data:
            # Store data in a file
            store(data, filename)

            print('pulled:', filename)
            print('--- waiting ---')
            time.sleep(15)



  from collections import Counter

def count_words():
    # Helper function definition
    def store_json(data, file):
        with open(file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print('Wrote file:', file)

    # Open and load titles from 'titles_clean.json'
    with open('titles_clean.json', 'r') as file:
        titles = json.load(file)
        words = []

        # Extract words and flatten
        for title in titles:
            words.extend(title.split())

        # Count word frequency
        counts = Counter(words)

        # Store word counts in 'words.json'
        store_json(counts, 'words.json')

        from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta
from airflow.utils.dates import days_ago

# Import your functions from assignment.py
from assignment import catalog, combine, titles, clean, count_words

# Define the DAG
with DAG(
    "assignment",
    start_date=days_ago(1),
    schedule_interval="@daily",
    catchup=False,
) as dag:

    # Define tasks
    t0 = BashOperator(
        task_id="task_zero",
        bash_command="pip install beautifulsoup4",
        retries=2
    )

    t1 = PythonOperator(
        task_id="task_one",
        depends_on_past=False,
        python_callable=catalog
    )

    t2 = PythonOperator(
        task_id="task_two",
        depends_on_past=False,
        python_callable=combine
    )

    t3 = PythonOperator(
        task_id="task_three",
        depends_on_past=False,
        python_callable=titles
    )

    t4 = PythonOperator(
        task_id="task_four",
        depends_on_past=False,
        python_callable=clean
    )

    t5 = PythonOperator(
        task_id="task_five",
        depends_on_past=False,
        python_callable=count_words
    )

    # Define task dependencies
    t0 >> t1 >> t2 >> t3 >> t4 >> t5

    <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>D3 Bubble Chart Example</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
</head>
<body>
    <div id="chart"></div>

    <script>
        // Load the JSON data from words.json
        d3.json("words.json").then(function(data) {
            // Modify the data structure if needed
            // For example, transform data to an array of objects with properties like 'name' and 'value'

            // Initialize the dimensions of the chart
            const width = 800;
            const height = 600;

            // Create the SVG container
            const svg = d3.select("#chart")
                .append("svg")
                .attr("width", width)
                .attr("height", height);

            // Define the scales and domain for the bubbles
            const radiusScale = d3.scaleLinear()
                .domain([0, d3.max(data, d => d.value)])
                .range([10, 100]);

            // Create and position the bubbles
            svg.selectAll("circle")
                .data(data)
                .enter()
                .append("circle")
                .attr("cx", d => Math.random() * width)
                .attr("cy", d => Math.random() * height)
                .attr("r", d => radiusScale(d.value))
                .attr("fill", "skyblue")
                .attr("opacity", 0.7);

            // Add labels to the bubbles
            svg.selectAll("text")
                .data(data)
                .enter()
                .append("text")
                .attr("x", d => Math.random() * width)
                .attr("y", d => Math.random() * height)
                .attr("text-anchor", "middle")
                .attr("alignment-baseline", "middle")
                .attr("font-size", "12px")
                .text(d => d.name);
        });
    </script>
</body>
</html>
